<img width="994" height="741" alt="image" src="https://github.com/user-attachments/assets/7658a033-9c59-473d-829c-7fe0b4a80d4c" />


# Machine Learning Powered Intelligent Credit Card Fraud Detection

This project focuses on building a complete, endâ€‘toâ€‘end machine learning pipeline to detect fraudulent credit card transactions using anonymized numerical features (V1â€“V28) along with the transaction Amount. The goal is to create a practical, dependable, and productionâ€‘ready fraud detection system that includes data processing, model training, evaluation, saving, and a userâ€‘friendly Streamlit interface.

---

## ğŸ“Œ Project Overview

Credit card fraud is a rare but highâ€‘impact problem. Most transactions are genuine, making fraud detection a highly imbalanced classification task. This project walks through the entire workflow of building an intelligent fraud detection modelâ€”from raw data all the way to a deployed UI.

The model predicts whether a given transaction is **fraudulent (1)** or **legitimate (0)** using machine learning, with a strong emphasis on proper data handling, class imbalance solutions, and clean deployment.

---

## ğŸš€ Project Workflow

Below is the exact workflow followed in this project:

### **ğŸŸ¦ Step 1: Data Ingestion**

* Load the raw credit card dataset (usually from Kaggle).
* Inspect column structure (V1â€“V28 + Amount + Class).
* Store raw files safely without modification.

### **ğŸŸ¥ Step 2: Exploratory Data Analysis (EDA)**

* Understand distribution of features.
* Analyze correlations and detect any anomalies.
* Review imbalance in the target variable.
* Visualize transaction Amount behavior for fraud vs nonâ€‘fraud.

### **ğŸŸª Step 3: Preprocessing**

* Scale numerical values (StandardScaler).
* Optional PCA if needed (depends on experimentation).
* Clean or transform Amount/Time appropriately.

### **ğŸŸ§ Step 4: Trainâ€‘Test Split**

* Use stratified splitting to preserve fraud ratio.
* Prevent leakage by splitting **before** any resampling.

### **ğŸŸ¨ Step 5: Handle Class Imbalance**

* Fraud cases are extremely rare, so imbalance handling is critical.
* Techniques evaluated:

  * Class weights
  * LightGBMâ€™s builtâ€‘in `is_unbalance` or `scale_pos_weight`
  * Oversampling (SMOTE)
  * Undersampling

### **ğŸŸ© Step 6: Model Building**

* Multiple models experimented with:

  * Logistic Regression
  * Random Forest
  * XGBoost
  * **LightGBM** (final choice)
* LightGBM performed best due to:

  * Great performance on highâ€‘dimensional numerical data
  * Fast training
  * Good handling of imbalance

### **ğŸŸ« Step 7: Final Model Selection**

* Evaluate models based on:

  * Precision, Recall, F1
  * ROCâ€‘AUC
  * PRâ€‘AUC (most important for imbalance)
* Select the best performing model (LightGBM).

### **â¬› Step 8: Saving the Final Model**

* A full pipeline was created using scikitâ€‘learn:

  * Preprocessing (Scaler/PCA)
  * LightGBM model
* Saved using `joblib` for deployment:

```
fraud_detection_pipeline.pkl
```

### **ğŸŸ« Step 9: Build Streamlit UI**

* A clean user interface was created to allow:

  * Manual input of V1â€“V28 + Amount
  * Realâ€‘time fraud prediction
  * Probability display for transparency
* The UI loads the saved pipeline and performs inference instantly.

---

##  Machine Learning Model

**Model Used:** LightGBM Classifier

**Why LightGBM?**

* Handles numerical, highâ€‘dimensional data well.
* Fast and scalable.
* Works better than XGBoost for heavily imbalanced datasets with fewer hyperparameters to tune.

**Key Features Used:**

* V1 â€“ V28 (PCAâ€‘transformed anonymized features)
* Amount

**Target:** `Class` â†’ 0 (Legit) / 1 (Fraud)

---

## ğŸ“Š Evaluation

Metrics considered:

* **Precision** (How many flagged transactions were actually fraud?)
* **Recall** (How many fraud transactions did the model catch?)
* **F1 Score** (Balance of precision & recall)
* **ROC-AUC**
* **PR-AUC** (best metric for this dataset)

The final LightGBM model achieved strong performance, especially in PRâ€‘AUC and recall, which are critical for realâ€‘world fraud detection.

---

## ğŸ’¾ Model Saving & Loading

The model is saved as a pipeline for clean inference:

```python
import joblib
pipeline = joblib.load("fraud_detection_pipeline.pkl")
prediction = pipeline.predict(input_data)
```

This ensures preprocessing and model prediction always match the training setup.

---

## ğŸ’» Streamlit App Features

* Clean UI for manually entering transaction details.
* Oneâ€‘click fraud prediction.
* Probability output to understand model confidence.
* Ready for deployment on Streamlit Cloud.

Run locally:

```bash
streamlit run streamlit_app.py
```

---



## ğŸ› ï¸ Tech Stack

* Python
* Pandas, NumPy
* Scikitâ€‘learn
* LightGBM
* Imbalancedâ€‘Learn
* Streamlit
* Matplotlib / Seaborn

---

##  How to Use this Project

1. Clone the repository.
2. Install required libraries.
3. Run training notebook if you want to retrain.
4. Launch UI using Streamlit.
5. Input feature values and get predictions instantly.

---

##  Future Improvements

* Add SHAP explainability in UI.
* Introduce FastAPI service for realâ€‘time API predictions.
* Add batch prediction support.
* Enable automatic retraining on new data.

---

## Acknowledgements

* Dataset sourced from Kaggleâ€™s Credit Card Fraud Detection dataset.
* Inspired by realâ€‘world transaction monitoring systems.

---

If you find this project useful, consider starring â­ the repository or contributing improvements!

